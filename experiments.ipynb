{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Subject-Dependent Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ADFD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Autoformer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model Autoformer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# Crossformer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model Crossformer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# FEDformer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model FEDformer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# Informer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model Informer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# iTransformer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model iTransformer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# MTST\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model MTST --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 8,32,96 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# Nonstationary_Transformer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model Nonstationary_Transformer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PatchTST\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model PatchTST --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# Reformer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model Reformer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# Transformer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model Transformer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# Medformer\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Dep --model Medformer --data ADFD-Dependent --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations drop0.5 --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Subject-Independent Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Autoformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Autoformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Autoformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Autoformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Autoformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Autoformer --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Crossformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Crossformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Crossformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Crossformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Crossformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Crossformer --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### FEDformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model FEDformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model FEDformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model FEDformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model FEDformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model FEDformer --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Informer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Informer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Informer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Informer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Informer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Informer --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### iTransformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model iTransformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model iTransformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model iTransformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model iTransformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model iTransformer --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MTST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model MTST --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 8,32,96 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model MTST --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 8,32,96 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model MTST --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 8,32,96 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model MTST --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 8,32,96 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model MTST --data PTB-XL --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 8,32,96 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Nonstationary_Transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Nonstationary_Transformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Nonstationary_Transformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Nonstationary_Transformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Nonstationary_Transformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Nonstationary_Transformer --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### PatchTST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model PatchTST --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model PatchTST --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model PatchTST --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model PatchTST --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model PatchTST --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Reformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Reformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Reformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Reformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Reformer --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Transformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Transformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Transformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Transformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Transformer --data PTB-XL --e_layers 6 --batch_size 256 --d_model 128 --d_ff 256 --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Medformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Medformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 2,2,2,4,4,4,16,16,16,16,32,32,32,32,32 --augmentations none,drop0.35 --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Medformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 8,8,8,16,16,16 --augmentations none,drop0.25 --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Medformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations drop0.5 --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Medformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,32,32,32,32,32 --augmentations none,drop0.5 --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "\n",
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Medformer --data PTB-XL --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations jitter0.2,scale0.2,drop0.5 --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ablation Study of Medformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APAVA Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Medformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 2,2,2,4,4,4,16,16,16,16,32,32,32,32,32 --augmentations none,drop0.35 --swa --no_inter_attn --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Medformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 2,2,2,4,4,4,16,16,16,16,32,32,32,32,32 --augmentations none --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/APAVA/ --model_id APAVA-Indep --model Medformer --data APAVA --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 2,2,2,4,4,4,16,16,16,16,32,32,32,32,32 --augmentations none,drop0.35 --swa --single_channel --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TDBRAIN Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Medformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 8,8,8,16,16,16 --augmentations none,drop0.25 --swa --no_inter_attn --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Medformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 8,8,8,16,16,16 --augmentations none --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/TDBRAIN/ --model_id TDBRAIN-Indep --model Medformer --data TDBRAIN --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 8,8,8,16,16,16 --augmentations none,drop0.25 --swa --single_channel --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ADFD Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Medformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations drop0.5 --swa --no_inter_attn --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Medformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations none --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/ADFD/ --model_id ADFD-Indep --model Medformer --data ADFD --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations drop0.5 --swa --single_channel --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PTB Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Medformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,32,32,32,32,32 --augmentations none,drop0.5 --swa --no_inter_attn --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Medformer --data PTB --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,32,32,32,32,32 --augmentations none --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB/ --model_id PTB-Indep --model Medformer --data PTB --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,32,32,32,32,32 --augmentations none,drop0.5 --swa --single_channel --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PTB-XL Dataset\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Medformer --data PTB-XL --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations jitter0.2,scale0.2,drop0.5 --swa --no_inter_attn --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Medformer --data PTB-XL --e_layers 6 --batch_size 128 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations none --swa --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10\n",
    "!python -u run.py --task_name classification --is_training 1 --root_path ./dataset/PTB-XL/ --model_id PTB-XL-Indep --model Medformer --data PTB-XL --e_layers 6 --batch_size 32 --d_model 128 --d_ff 256 --patch_len_list 2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32 --augmentations jitter0.2,scale0.2,drop0.5 --swa --single_channel --des 'Exp' --itr 5 --learning_rate 0.0001 --train_epochs 100 --patience 10"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
